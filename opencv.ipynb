{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "print(cv2.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 #0 for gray scale 1 for color -1 for alpha channel\n",
    "a=cv2.imread(\"opencv-master\\samples\\data\\lena.jpg\",0)\n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"image\",a) #image is window dialouge name\n",
    "k=cv2.waitKey(0)  #waitkey telss tiem which ur windwow will show 5 sec\n",
    "if k==27: #27 means escape key  every waitkey value has some meaning\n",
    "    cv2.destroyAllWindows()\n",
    "elif k==ord('s'):#ord is a builtint function which takes one argument\n",
    "    cv2.imwrite(\"lenaalter.png\",a)    \n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"imread\n",
    "imshow\n",
    "waitkey   or &0xFF\n",
    "imwrite\n",
    "destroyAllWindows\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cap=cv2.VideoCapture(0)# 0 or-1  and 1 for multple camera \n",
    "while(True):\n",
    "    ret,frame=cap.read()#ret save true false and frame save frame\n",
    "    cv2.imshow(\"frame\",frame)    \n",
    "    if cv2.waitKey(1)&0xFF==ord(\"q\"):\n",
    "        break\n",
    "cap.release()#Closes video file or capturing device.\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cap=cv2.VideoCapture(0)# 0 or-1  and 1 for multple camera \n",
    "while(True):\n",
    "    ret,frame=cap.read()#ret save true false and frame save frame\n",
    "    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)#cvt is convert  bluegreen red to gray\n",
    "    cv2.imshow(\"frame\",gray)    \n",
    "    if cv2.waitKey(1)&0xFF==ord(\"q\"):\n",
    "        break\n",
    "cap.release()#Closes video file or capturing device.\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cap=cv2.VideoCapture(0)# 0 or-1  and 1 for multple camera \n",
    "\n",
    "fourcc=cv2.VideoWriter_fourcc(*'XVID') #fourcc is website which provides funtion\n",
    "out=cv2.VideoWriter(\"output.avi\",fourcc,20.0,(640,480))#20.0 is frame rate\n",
    "while(cap.isOpened()):\n",
    "    ret,frame=cap.read()#ret save true false and frame save frame\n",
    "    if ret==True:\n",
    "       # print(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        #print(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        out.write(frame)\n",
    "        gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)#cvt is convert  bluegreen red to gray\n",
    "        cv2.imshow(\"frame\",gray)    \n",
    "        if cv2.waitKey(1) & 0xFF==ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "            break\n",
    "cap.release()#Closes video file or capturing device.\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "img=cv2.imread('opencv-master\\samples\\data\\lena.jpg',1)#here bgr format is used not rgb\n",
    "img=cv2.line(img,(0,0),(255,255),(0,0,255),10)#img var,unital poitn,final point,color format ,last one is thickness\n",
    "img=cv2.arrowedLine(img,(0,255),(255,255),(255,0,0),10)\n",
    "cv2.imshow(\"image\",img) #image is window dialouge name\n",
    "cv2.waitKey(0)  #waitkey telss tiem which ur windwow will show 5 sec\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "img=cv2.imread('opencv-master\\samples\\data\\lena.jpg',1)#here bgr format is used not rgb\n",
    "img=cv2.rectangle(img,(384,0),(510,128),(255,0,0),10)#2 argumnt is top left and 3 is below right\n",
    "cv2.imshow(\"image\",img) #image is window dialouge name  esc for close window\n",
    "cv2.waitKey(0)  #waitkey telss tiem which ur windwow will show 5 sec\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "img=cv2.imread('uhk.jpg',1)#here bgr format is used not rgb\n",
    "img=cv2.circle(img,(447,63),63,(0,255,0),-1)#2 argumnt is centre of circle and 3 is radius  4 is bgr 5 is -1 show fill green color in circle\n",
    "font=cv2.FONT_HERSHEY_SIMPLEX\n",
    "img=cv2.putText(img,\"uhk\",(10,500),font,4,(255,255,255),10,cv2.LINE_AA)#3 is starting point  4 font  5 font size ,6 bgr,7 thickness,type of line\n",
    "cv2.imshow(\"image\",img) #image is window dialouge name  esc for close window\n",
    "cv2.waitKey(0)  #waitkey telss tiem which ur windwow will show 5 sec\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "img=cv2.imread('uhk.jpg',1)#here bgr format is used not rgb\n",
    "img=cv2.line(img,(0,0),(255,255),(0,0,255),10)#img var,unital poitn,final point,color format ,last one is thickness\n",
    "img=cv2.arrowedLine(img,(0,255),(255,255),(255,0,0),10)\n",
    "img=cv2.rectangle(img,(384,0),(510,128),(255,0,0),10)\n",
    "img=cv2.circle(img,(447,63),63,(0,255,0),-1)#2 argumnt is centre of circle and 3 is radius  4 is bgr 5 is -1 show fill green color in circle\n",
    "font=cv2.FONT_HERSHEY_SIMPLEX\n",
    "img=cv2.putText(img,\"uhk\",(10,500),font,4,(255,255,255),10,cv2.LINE_AA)#3 is starting point  4 font  5 font size ,6 bgr,7 thickness,type of line\n",
    "cv2.imshow(\"image\",img) #image is window dialouge name  esc for close window\n",
    "cv2.waitKey(0)  #waitkey telss tiem which ur windwow will show 5 sec\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "img=np.zeros([512,512,3],np.uint8)# 512 and 512 is width heoght nad  3 is colr  annd ;ast one is datatype\n",
    "img=cv2.line(img,(0,0),(255,255),(0,0,255),10)#img var,unital poitn,final point,color format ,last one is thickness\n",
    "img=cv2.arrowedLine(img,(0,255),(255,255),(255,0,0),10)\n",
    "img=cv2.rectangle(img,(384,0),(510,128),(255,0,0),10)\n",
    "img=cv2.circle(img,(447,63),63,(0,255,0),-1)#2 argumnt is centre of circle and 3 is radius  4 is bgr 5 is -1 show fill green color in circle\n",
    "font=cv2.FONT_HERSHEY_SIMPLEX\n",
    "img=cv2.putText(img,\"uhk\",(10,500),font,4,(255,255,255),10,cv2.LINE_AA)#3 is starting point  4 font  5 font size ,6 bgr,7 thickness,type of line\n",
    "cv2.imshow(\"image\",img) #image is window dialouge name  esc for close window\n",
    "cv2.waitKey(0)  #waitkey telss tiem which ur windwow will show 5 sec\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "changing width\n",
    "\"\"\"\n",
    "import cv2\n",
    "cap=cv2.VideoCapture(0)# 0 or-1  and 1 for multple camera \n",
    "print(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "print(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "cap.set(3,1208)# 3 equivalnet to cv2.CAP_PROP_FRAME_WIDTH\n",
    "cap.set(4,720)#4 equivalnet to cv2.CAP_PROP_FRAME_HEIGHT\n",
    "print(cap.get(3)) #after changing width\n",
    "print(cap.get(4))#after chaniging heght but resolultion willbbe same\n",
    "while(cap.isOpened()):\n",
    "    ret,frame=cap.read()#ret save true false and frame save frame\n",
    "    if ret==True:\n",
    "       # print(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        #print(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        #out.write(frame)\n",
    "        gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)#cvt is convert  bluegreen red to gray\n",
    "        cv2.imshow(\"frame\",gray)    \n",
    "        if cv2.waitKey(1) & 0xFF==ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "            break\n",
    "cap.release()#Closes video file or capturing device.\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how to draw shapes on vodes and  define date and time\n",
    "import datetime\n",
    "import cv2\n",
    "cap=cv2.VideoCapture(0)# 0 or-1  and 1 for multple camera \n",
    "print(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "print(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "cap.set(3,1208)# 3 equivalnet to cv2.CAP_PROP_FRAME_WIDTH\n",
    "cap.set(4,720)#4 equivalnet to cv2.CAP_PROP_FRAME_HEIGHT\n",
    "print(cap.get(3)) #after changing width\n",
    "print(cap.get(4))#after chaniging heght but resolultion willbbe same\n",
    "while(cap.isOpened()):\n",
    "    ret,frame=cap.read()#ret save true false and frame save frame\n",
    "    if ret==True:\n",
    "        font=cv2.FONT_HERSHEY_SIMPLEX\n",
    "        text=\"width:\"+str(cap.get(3))+\"height:\"+str(cap.get(4))\n",
    "        dated=str(datetime.datetime.now())\n",
    "        frame=cv2.putText(frame,dated,(10,50),font,1,(0,255,255),2,cv2.LINE_AA)\n",
    "        cv2.imshow(\"frame\",frame)    \n",
    "        if cv2.waitKey(1) & 0xFF==ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "            break\n",
    "cap.release()#Closes video file or capturing device.\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import cv2\n",
    "cap=cv2.VideoCapture(0)# 0 or-1  and 1 for multple camera \n",
    "print(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "print(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "cap.set(3,1208)# 3 equivalnet to cv2.CAP_PROP_FRAME_WIDTH\n",
    "cap.set(4,720)#4 equivalnet to cv2.CAP_PROP_FRAME_HEIGHT\n",
    "print(cap.get(3)) #after changing width\n",
    "print(cap.get(4))#after chaniging heght but resolultion willbbe same\n",
    "while(cap.isOpened()):\n",
    "    ret,frame=cap.read()#ret save true false and frame save frame\n",
    "    if ret==True:\n",
    "        font=cv2.FONT_HERSHEY_SIMPLEX\n",
    "        text=\"width:\"+str(cap.get(3))+\"height:\"+str(cap.get(4))\n",
    "        frame=cv2.putText(frame,text,(10,50),font,1,(0,255,255),2,cv2.LINE_AA)\n",
    "        cv2.imshow(\"frame\",frame)    \n",
    "        if cv2.waitKey(1) & 0xFF==ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "            break\n",
    "cap.release()#Closes video file or capturing device.\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "events=[i for i in dir(cv2) if \"EVENT\" in i]\n",
    "print(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "def click_event(event,x,y,flags,param):#secif parameter alywasy useas\n",
    "        if event==cv2.EVENT_LBUTTONDOWN:\n",
    "            print(x,'',y)\n",
    "            font=cv2.FONT_HERSHEY_SIMPLEX\n",
    "            strXY=str(x)+','+str(y)\n",
    "            cv2.putText(img,strXY,(x,y),font,1,(255,255,0),2)\n",
    "            cv2.imshow('image',img)\n",
    "img=np.zeros((512,512,3),np.uint8)\n",
    "cv2.imshow('image',img)\n",
    "cv2.setMouseCallback('image',click_event)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "def click_event(event,x,y,flags,param):#secif parameter alywasy useas\n",
    "        if event==cv2.EVENT_LBUTTONDOWN:\n",
    "            print(x,'',y)\n",
    "            font=cv2.FONT_HERSHEY_SIMPLEX\n",
    "            strXY=str(x)+','+str(y)\n",
    "            cv2.putText(img,strXY,(x,y),font,1,(255,255,0),2)\n",
    "            cv2.imshow('image',img)\n",
    "        if event==cv2.EVENT_RBUTTONDOWN:\n",
    "            blue=img[y,x,0]\n",
    "            red=img[y,x,2]\n",
    "            green=img[y,x,1]\n",
    "            font=cv2.FONT_HERSHEY_SIMPLEX\n",
    "            strBGR=str(blue)+','+str(green)+','+str(red)\n",
    "            cv2.putText(img,strBGR,(x,y),font,1,(0,255,255),2)\n",
    "            cv2.imshow('image',img) \n",
    "img=np.zeros((512,512,3),np.uint8)\n",
    "cv2.imshow('image',img)\n",
    "cv2.setMouseCallback('image',click_event)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "def click_event(event,x,y,flags,param):#secif parameter alywasy useas\n",
    "        if event==cv2.EVENT_LBUTTONDOWN:\n",
    "            print(x,'',y)\n",
    "            font=cv2.FONT_HERSHEY_SIMPLEX\n",
    "            strXY=str(x)+','+str(y)\n",
    "            cv2.putText(img,strXY,(x,y),font,1,(255,255,0),2)\n",
    "            cv2.imshow('image',img)\n",
    "        if event==cv2.EVENT_RBUTTONDOWN:\n",
    "            blue=img[y,x,0]\n",
    "            red=img[y,x,2]\n",
    "            green=img[y,x,1]\n",
    "            font=cv2.FONT_HERSHEY_SIMPLEX\n",
    "            strBGR=str(blue)+','+str(green)+','+str(red)\n",
    "            cv2.putText(img,strBGR,(x,y),font,1,(0,255,255),2)\n",
    "            cv2.imshow('image',img) \n",
    "img=cv2.imread(\"uhk.jpg\")\n",
    "cv2.imshow('image',img)\n",
    "cv2.setMouseCallback('image',click_event)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img=cv2.imread(\"opencv-master\\samples\\data\\messi5.jpg\")\n",
    "print(img.shape)\n",
    "print(img.size)\n",
    "print(img.dtype)\n",
    "b,g,r=cv2.split(img)\n",
    "img=cv2.merge((b,g,r))\n",
    "cv2.imshow(\"image\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#roi region of intrest\n",
    "import cv2\n",
    "img=cv2.imread(\"opencv-master\\samples\\data\\messi5.jpg\")\n",
    "print(img.shape)\n",
    "print(img.size)\n",
    "print(img.dtype)\n",
    "b,g,r=cv2.split(img)\n",
    "img=cv2.merge((b,g,r))\n",
    "ball=img[280:340,330:390]\n",
    "img[273:333,100:160]=ball\n",
    "cv2.imshow(\"image\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how add image to other image\n",
    "import cv2\n",
    "img=cv2.imread(\"opencv-master\\samples\\data\\messi5.jpg\")\n",
    "img2=cv2.imread(\"opencv-master\\samples\\data\\opencv-logo.png\")\n",
    "print(img.shape)\n",
    "print(img.size)\n",
    "print(img.dtype)\n",
    "b,g,r=cv2.split(img)\n",
    "img=cv2.merge((b,g,r))\n",
    "ball=img[280:340,330:390]\n",
    "img[273:333,100:160]=ball\n",
    "\n",
    "img=cv2.resize(img,(512,512))\n",
    "img2=cv2.resize(img2,(512,512))\n",
    "dest=cv2.add(img,img2)\n",
    "dest=cv2.addWeighted(img,.8,img2,.2,0) #0 is gamma value waiigh is basically a opaciyty  weight should not be greater than 1 \n",
    "cv2.imshow(\"image\",dest)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bitwise images 1 1 1 only black black black black white blaice black 0 white 1\n",
    "#use when mass is need\n",
    "#bitewise or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img1=np.zeros((250,500,3),np.uint8)\n",
    "img1=cv2.rectangle(img1,(200,0),(300,100),(255,255,255),-1) #-1 shlws rect fill with white color\n",
    "img2=cv2.imread(\"opencv-master\\samples\\data\\image1.png\")\n",
    "bitAnd=cv2.bitwise_and(img2,img1)\n",
    "cv2.imshow(\"img1\",img1)\n",
    "cv2.imshow(\"img2\",img2)\n",
    "cv2.show(\"bitand\",bitAnd)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "def nothing (x):\n",
    "    print(x)\n",
    "img=np.zeros((300,512,3),np.uint8)\n",
    "cv2.namedWindow(\"image\")\n",
    "cv2.createTrackbar('R',\"image\",0,255,nothing)\n",
    "cv2.createTrackbar('G',\"image\",0,255,nothing)\n",
    "cv2.createTrackbar('B',\"image\",0,255,nothing)\n",
    "\n",
    "while(1):\n",
    "    cv2.imshow(\"image\",img)\n",
    "    k=cv2.waitKey(1)&0XFF\n",
    "    if k==27:\n",
    "        break\n",
    "    b=cv2.getTrackbarPos('B',\"image\")\n",
    "    g=cv2.getTrackbarPos('G',\"image\")\n",
    "    r=cv2.getTrackbarPos('R',\"image\")\n",
    "    img[:]=[b,g,r]\n",
    "cv2.destroyAllWindows()    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def nothing (x):\n",
    "    print(x)\n",
    "img=np.zeros((300,512,3),np.uint8)\n",
    "cv2.namedWindow(\"image\")\n",
    "cv2.createTrackbar('R',\"image\",0,255,nothing)\n",
    "cv2.createTrackbar('G',\"image\",0,255,nothing)\n",
    "cv2.createTrackbar('B',\"image\",0,255,nothing)\n",
    "switch='0:off \\n 1:on'\n",
    "cv2.createTrackbar(switch,\"image\",0,1,nothing)        \n",
    "while(1):\n",
    "    cv2.imshow(\"image\",img)\n",
    "    k=cv2.waitKey(1)&0XFF\n",
    "    if k==27:\n",
    "        break\n",
    "    b=cv2.getTrackbarPos('B',\"image\")\n",
    "    g=cv2.getTrackbarPos('G',\"image\")\n",
    "    r=cv2.getTrackbarPos('R',\"image\")\n",
    "    s=cv2.getTrackbarPos(switch,\"image\")\n",
    "    if s==0:\n",
    "        img[:]=0 \n",
    "    else: \n",
    "        img[:]=[b,g,r]\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#13\n",
    "import numpy as np\n",
    "def nothing (x):\n",
    "    print(x)\n",
    "img=cv2.imread('opencv-master\\samples\\data\\lena.jpg')\n",
    "cv2.namedWindow(\"image\")\n",
    "cv2.createTrackbar('cp',\"image\",10,400,nothing)\n",
    "\n",
    "switch='color/gray'\n",
    "cv2.createTrackbar(switch,\"image\",0,1,nothing)        \n",
    "while(1):\n",
    "    img=cv2.imread('opencv-master\\samples\\data\\lena.jpg')\n",
    "    pos=cv2.getTrackbarPos('cp','image')\n",
    "    font=cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(img,str(pos),(50,150),font,4,(0,0,255))\n",
    "    k=cv2.waitKey(1)&0XFF\n",
    "    if k==27:\n",
    "        break\n",
    "    \n",
    "    s=cv2.getTrackbarPos('switch',\"image\")\n",
    "    if s==0:\n",
    "        pass \n",
    "    else: \n",
    "        img=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#14 hsv hue situration value\n",
    "import numpy as np\n",
    "import  cv2\n",
    "while True:\n",
    "    frame=cv2.imread(\"opencv-master\\samples\\data\\smarties.png\")\n",
    "    hsv=cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)\n",
    "    l_b=np.array([110,50,50])\n",
    "    u_b=np.array([130,255,255])\n",
    "    mask=cv2.inRange(hsv,l_b,u_b)\n",
    "    res=cv2.bitwise_and(frame,frame,mask=mask)\n",
    "    cv2.imshow('frame',frame)\n",
    "    cv2.imshow('mask',mask)\n",
    "    cv2.imshow('res',res)\n",
    "    key=cv2.waitKey(1)\n",
    "    if key==27:\n",
    "        break\n",
    "        cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#14 hsv hue situration value\n",
    "import numpy as np\n",
    "import  cv2\n",
    "def nothing(x):\n",
    "    pass\n",
    "cv2.namedWindow(\"tracking\")\n",
    "cv2.createTrackbar(\"LH\",\"Tracking\",0,255,nothing)\n",
    "cv2.createTrackbar(\"LS\",\"Tracking\",0,255,nothing)\n",
    "cv2.createTrackbar(\"LV\",\"Tracking\",0,255,nothing)\n",
    "cv2.createTrackbar(\"UH\",\"Tracking\",255,255,nothing)\n",
    "cv2.createTrackbar(\"UH\",\"Tracking\",255,255,nothing)\n",
    "cv2.createTrackbar(\"US\",\"Tracking\",255,255,nothing)\n",
    "\n",
    "\n",
    "while True:\n",
    "    frame=cv2.imread(\"opencv-master\\samples\\data\\smarties.png\")\n",
    "    hsv=cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)\n",
    "    l_h=cv2.getTrackbarPos(\"LH\",\"Tracking\")\n",
    "    l_s=cv2.getTrackbarPos(\"LS\",\"Tracking\")\n",
    "    l_v=cv2.getTrackbarPos(\"LV\",\"Tracking\")\n",
    "    \n",
    "    u_h=cv2.getTrackbarPos(\"UH\",\"Tracking\")\n",
    "    u_s=cv2.getTrackbarPos(\"US\",\"Tracking\")\n",
    "    u_v=cv2.getTrackbarPos(\"UV\",\"Tracking\")\n",
    "    l_b=np.array([l_h,l_s,l_v])\n",
    "    u_b=np.array([u_h,u_s,u_v])\n",
    "    mask=cv2.inRange(hsv,l_b,u_b)\n",
    "    res=cv2.bitwise_and(frame,frame,mask=mask)\n",
    "    cv2.imshow('frame',frame)\n",
    "    cv2.imshow('mask',mask)\n",
    "    cv2.imshow('res',res)\n",
    "    key=cv2.waitKey(1)\n",
    "    if key==27:\n",
    "        break\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#threshold if less than 127 so 0 black if greater than 127 so 1 whiet \n",
    "import cv2 \n",
    "img=cv2.imread(\"opencv-master\\samples\\data\\gradient.png\",0)\n",
    "_,th1=cv2.threshold(img,127,255,cv2.THRESH_BINARY) #threhs give 2 value is is thrshld other is ret\n",
    "cv2.imshow('th1',th1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "img=cv2.imread(\"opencv-master\\samples\\data\\gradient.png\",0)\n",
    "_,th1=cv2.threshold(img,127,255,cv2.THRESH_BINARY_INV) #threhs give 2 value is is thrshld other is ret\n",
    "cv2.imshow('th1',th1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "img=cv2.imread(\"opencv-master\\samples\\data\\gradient.png\",0)\n",
    "_,th1=cv2.threshold(img,127,255,cv2.THRESH_TRUNC) #threhs give 2 value is is thrshld other is ret\n",
    "cv2.imshow('th1',th1)#if calue is less than 127 so no change is greater so value wiill be change as before\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "img=cv2.imread(\"opencv-master\\samples\\data\\gradient.png\",0)\n",
    "_,th1=cv2.threshold(img,127,255,cv2.THRESH_TOZERO) #threhs give 2 value is is thrshld other is ret\n",
    "cv2.imshow('th1',th1)#if calue is less than 127 so 0 IF greater so value wiill be change as before\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "img=cv2.imread(\"opencv-master\\samples\\data\\gradient.png\",0)\n",
    "_,th1=cv2.threshold(img,127,255,cv2.THRESH_TOZERO_INV) #threhs give 2 value is is thrshld other is ret\n",
    "cv2.imshow('th1',th1)#if calue is less than 127 so 0 IF greater so value wiill be change as before\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adaptive  threshold\n",
    "#calculats for small region\n",
    "import cv2\n",
    "img=cv2.imread(\"opencv-master\\samples\\data\\sudoku.png\",0)\n",
    "_,th1=cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "th2=cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,11,2)\n",
    "th3=cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n",
    "cv2.imshow('Image',img)\n",
    "cv2.imshow('th1',th1)\n",
    "cv2.imshow('th2',th2)\n",
    "cv2.imshow('th2',th2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matplotlib officaial websote matplotlib.org\n",
    "#matplotlib follow rgb unlike opencv\n",
    "from matplotlib import pyplot as plt\n",
    "img=cv2.imread(\"opencv-master\\samples\\data\\lena.jpg\",-1)\n",
    "cv2.imshow('image',img)\n",
    "img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)\n",
    "#plt.xticks([]),plt.yticks([])\n",
    "plt.show()\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "from matplotlib import pyplot as plt\n",
    "img=cv2.imread(\"opencv-master\\samples\\data\\gradient.png\",0)\n",
    "_,th1=cv2.threshold(img,50,255,cv2.THRESH_BINARY) #threhs give 2 value is is thrshld other is ret\n",
    "_,th2=cv2.threshold(img,200,255,cv2.THRESH_BINARY_INV)\n",
    "_,th3=cv2.threshold(img,127,255,cv2.THRESH_TRUNC)\n",
    "_,th4=cv2.threshold(img,127,255,cv2.THRESH_TOZERO)\n",
    "_,th5=cv2.threshold(img,127,255,cv2.THRESH_TOZERO_INV)\n",
    "titles=['original image','binary','binary inv','trunch','tozero','tozero_inv']\n",
    "images=[img,th1,th2,th3,th4,th5]\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1),plt.imshow(images[i],'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "plt.show()    \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#morphological transformation arre some simple operation bassed on images shape\n",
    "#twho thins is required 1) original image 2)struxre elemen or kernal whcih desice operatioj\n",
    "\n",
    "#binary iamge\n",
    "import cv2\n",
    "from matplotlib import  pyplot as plt# img must be in gray scale\n",
    "img=cv2.imread(\"opencv-master\\samples\\data\\smarties.png\",0) \n",
    "_,mask=cv2.threshold(img,220,255,cv2.THRESH_BINARY_INV)#255 always bcs  maximim\n",
    "titles=['image','mask']\n",
    "images=[img,mask]\n",
    "for i in range(2):\n",
    "    plt.subplot(1,2,i+1),plt.imshow(images[i],'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keranl is normay a shae sqaure or circle which we wana apply\n",
    "#morphological transformation arre some simple operation bassed on images shape\n",
    "#twho thins is required 1) original image 2)struxre elemen or kernal whcih desice operatioj\n",
    "\n",
    "#binary iamge\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import  pyplot as plt# img must be in gray scale\n",
    "img=cv2.imread(\"opencv-master\\samples\\data\\smarties.png\",0) \n",
    "_,mask=cv2.threshold(img,220,255,cv2.THRESH_BINARY_INV)#255 always bcs  maximim\n",
    "kernal=np.ones((2,2),np.uint8) #if u ncrease the size ofkernal  u can  increase circle\n",
    "#kernal makes squre of circle whihh u wana spot black\n",
    "dilation=cv2.dilate(mask,kernal,iterations=2) #iterations ind ilation no of times u wana perfrom dialtion default is 1\n",
    "#dilation redue the black dots\n",
    "erosion=cv2.erode(mask,kernal,iterations=1)\n",
    "opening=cv2.morphologyEx(mask,cv2.MORPH_OPEN,kernal)\n",
    "closing=cv2.morphologyEx(mask,cv2.MORPH_CLOSE,kernal)\n",
    "mg=cv2.morphologyEx(mask,cv2.MORPH_GRADIENT,kernal)\n",
    "th=cv2.morphologyEx(mask,cv2.MORPH_TOPHAT,kernal)\n",
    "titles=['image','mask','dilation','erosion','opening','closing','mg','th']\n",
    "images=[img,mask,dilation,erosion,opening,closing,mg,th]\n",
    "for i in range(8):\n",
    "    plt.subplot(2,4,i+1),plt.imshow(images[i],'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "plt.show()\n",
    "#erosion sharpning the boundry\n",
    "#opening  do first erosion perfom than  dialtion \n",
    "#closing do first dilation than erosion\n",
    "#morphological gradient is the dff od dilation and erosion\n",
    "#tophat iss diff of image and opening of of image\n",
    "#if image is binary so dont use mask us image directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keranl is normay a shae sqaure or circle which we wana apply\n",
    "#morphological transformation arre some simple operation bassed on images shape\n",
    "#twho thins is required 1) original image 2)struxre elemen or kernal whcih desice operatioj\n",
    "\n",
    "#binary iamge\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import  pyplot as plt# img must be in gray scale\n",
    "img=cv2.imread(\"opencv-master\\samples\\data\\LinuxLogo.jpg\",cv2.IMREAD_GRAYSCALE) \n",
    "#_,mask=cv2.threshold(img,220,255,cv2.THRESH_BINARY_INV)#255 always bcs  maximim\n",
    "kernal=np.ones((2,2),np.uint8) #if u ncrease the size ofkernal  u can  increase circle\n",
    "#kernal makes squre of circle whihh u wana spot black\n",
    "dilation=cv2.dilate(img,kernal,iterations=2) #iterations ind ilation no of times u wana perfrom dialtion default is 1\n",
    "#dilation redue the black dots\n",
    "erosion=cv2.erode(img,kernal,iterations=1)\n",
    "opening=cv2.morphologyEx(img,cv2.MORPH_OPEN,kernal)\n",
    "closing=cv2.morphologyEx(img,cv2.MORPH_CLOSE,kernal)\n",
    "mg=cv2.morphologyEx(img,cv2.MORPH_GRADIENT,kernal)\n",
    "th=cv2.morphologyEx(img,cv2.MORPH_TOPHAT,kernal)\n",
    "titles=['image','mask','dilation','erosion','opening','closing','mg','th']\n",
    "images=[img,img,dilation,erosion,opening,closing,mg,th]\n",
    "for i in range(8):\n",
    "    plt.subplot(2,4,i+1),plt.imshow(images[i],'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "plt.show()\n",
    "#erosion sharpning the boundry\n",
    "#opening  do first erosion perfom than  dialtion \n",
    "#closing do first dilation than erosion\n",
    "#morphological gradient is the dff od dilation and erosion\n",
    "#tophat iss diff of image and opening of of image\n",
    "#if image is binary so dont use mask us image directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#smoothing \n",
    "#homogeneous filter ,gausian filter,median filter,bilateral filter\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('opencv-master\\samples\\data\\lena.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "kernel = np.ones((5, 5), np.float32)/25 #25 is5*5\n",
    "dst = cv2.filter2D(img, -1, kernel)#filter 2d is use for homogeneous filter -1 used  for desire depth of destination images(sharpening images)\n",
    "blur = cv2.blur(img, (5, 5))#use avaeraging algorithm to bluring the images\n",
    "gblur = cv2.GaussianBlur(img, (5, 5), 0)#gausing filter algo kernal central value myust be greater\n",
    "median = cv2.medianBlur(img, 5)#meaidan filter mean the pixel if u have dot in images u can remove through this\n",
    "bilateralFilter = cv2.bilateralFilter(img, 9, 75, 75)#edges prserved good boundrry sharp\n",
    "\n",
    "titles = ['image', '2D Convolution', 'blur', 'GaussianBlur', 'median', 'bilateralFilter']\n",
    "images = [img, dst, blur, gblur, median, bilateralFilter]\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2, 3, i+1), plt.imshow(images[i], 'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "\n",
    "plt.show()\n",
    "#homogeneous filter ,each pixel is a weight of kernal neigh bour\n",
    "#kernal =1/width*height[]\n",
    "#2d convolution sharpeing the edges(boubbdry)\n",
    "\"\"\"\n",
    "one dimension signals images alos can be fltered with \n",
    "various low pass filters lpf and high pass filters\n",
    "lpf helps in removing noises bluring th images\n",
    "hpf filters helps in finding edges in the images\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "image gradient\n",
    "diectional changes in the insoty or color in an images\"\"\"\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread(\"opencv-master\\samples\\data\\sudoku.png\", cv2.IMREAD_GRAYSCALE)\n",
    "lap = cv2.Laplacian(img, cv2.CV_64F, ksize=3)#laplacian gradient cv_64 is data type its suppor the negative numberrs\n",
    "#edges can be detect thoru lablacian ksize is kernal size\n",
    "#sobel or sobel gradient 1means soebl x  for x dieeecton 0 for orde rof derative y  \n",
    "lap = np.uint8(np.absolute(lap))\n",
    "sobelX = cv2.Sobel(img, cv2.CV_64F, 1, 0)\n",
    "sobelY = cv2.Sobel(img, cv2.CV_64F, 0, 1)\n",
    "\n",
    "sobelX = np.uint8(np.absolute(sobelX))\n",
    "sobelY = np.uint8(np.absolute(sobelY))\n",
    "\n",
    "sobelCombined = cv2.bitwise_or(sobelX, sobelY)\n",
    "\n",
    "titles = ['image', 'Laplacian', 'sobelX', 'sobelY', 'sobelCombined']\n",
    "images = [img, lap, sobelX, sobelY, sobelCombined]\n",
    "for i in range(5):\n",
    "    plt.subplot(2, 3, i+1), plt.imshow(images[i], 'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cany edge detector  detect edges \n",
    "\n",
    "\"\"\"\"1)noise reduction\n",
    "2) gradiaent calculation\n",
    "3) non maximum suppression\n",
    "4)double threeshold\n",
    "5) edge tracking by hysteresis\"\"\"\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread(\"opencv-master\\samples\\data\\lena.jpg\")\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "canny = cv2.Canny(img, 100, 200) #100 is threshold 1 200 is threshold2\n",
    "\n",
    "titles = ['image', 'canny']\n",
    "images = [img, canny]\n",
    "for i in range(2):\n",
    "    plt.subplot(1, 2, i+1), plt.imshow(images[i], 'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread(\"opencv-master\\samples\\data\\messi5.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "lap = cv2.Laplacian(img, cv2.CV_64F, ksize=3)\n",
    "lap = np.uint8(np.absolute(lap))\n",
    "sobelX = cv2.Sobel(img, cv2.CV_64F, 1, 0)\n",
    "sobelY = cv2.Sobel(img, cv2.CV_64F, 0, 1)\n",
    "edges = cv2.Canny(img,100,200)\n",
    "\n",
    "sobelX = np.uint8(np.absolute(sobelX))\n",
    "sobelY = np.uint8(np.absolute(sobelY))\n",
    "\n",
    "sobelCombined = cv2.bitwise_or(sobelX, sobelY)\n",
    "\n",
    "titles = ['image', 'Laplacian', 'sobelX', 'sobelY', 'sobelCombined', 'Canny']\n",
    "images = [img, lap, sobelX, sobelY, sobelCombined, edges]\n",
    "for i in range(6):\n",
    "    plt.subplot(2, 3, i+1), plt.imshow(images[i], 'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image pyramid\n",
    "#pyrdown reduce the resolution of image with respct to size\n",
    "#once ur pyrdown then u pyrup bur informatio lost but u can do\n",
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread(\"opencv-master\\samples\\data\\lena.jpg\")\n",
    "layer = img.copy()\n",
    "gaussian_pyramid_list = [layer]\n",
    "\n",
    "for i in range(6):\n",
    "    layer = cv2.pyrDown(layer)\n",
    "    gaussian_pyramid_list.append(layer)\n",
    "    #cv2.imshow(str(i), layer)\n",
    "\n",
    "layer = gaussian_pyramid_list[5]\n",
    "cv2.imshow('upper level Gaussian Pyramid', layer)\n",
    "laplacian_pyramid_list = [layer]\n",
    "\n",
    "for i in range(5, 0, -1):\n",
    "    gaussian_extended = cv2.pyrUp(gaussian_pyramid_list[i])\n",
    "    laplacian = cv2.subtract(gaussian_pyramid_list[i-1], gaussian_extended)\n",
    "    cv2.imshow(str(i), laplacian)\n",
    "\n",
    "cv2.imshow(\"Original image\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread(\"opencv-master\\samples\\data\\lena.jpg\")\n",
    "layer = img.copy()\n",
    "gp = [layer]\n",
    "for i in range(6):\n",
    "    layer = cv2.pyrDown(layer)\n",
    "    gp.append(layer)\n",
    "    cv2.imshow(str(i), layer)\n",
    "cv2.imshow(\"Original image\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image blending(merge)\n",
    "import cv2\n",
    "import numpy as np\n",
    "apple = cv2.imread('opencv-master\\samples\\data\\lena.jpg')\n",
    "orange = cv2.imread('opencv-master\\samples\\data\\orange.jpg')\n",
    "print(apple.shape)\n",
    "print(orange.shape)\n",
    "apple_orange = np.hstack((apple[:, :256], orange[:, 256:]))\n",
    "\n",
    "# generate Gaussian pyramid for apple\n",
    "apple_copy = apple.copy()\n",
    "gp_apple = [apple_copy]\n",
    "for i in range(6):\n",
    "    apple_copy = cv2.pyrDown(apple_copy)\n",
    "    gp_apple.append(apple_copy)\n",
    "\n",
    "\n",
    "# generate Gaussian pyramid for orange\n",
    "orange_copy = orange.copy()\n",
    "gp_orange = [orange_copy]\n",
    "for i in range(6):\n",
    "    orange_copy = cv2.pyrDown(orange_copy)\n",
    "    gp_orange.append(orange_copy)\n",
    "\n",
    "# generate Laplacian Pyramid for apple\n",
    "apple_copy = gp_apple[5]\n",
    "lp_apple = [apple_copy]\n",
    "for i in range(5, 0, -1):\n",
    "    gaussian_expanded = cv2.pyrUp(gp_apple[i])\n",
    "    laplacian = cv2.subtract(gp_apple[i-1], gaussian_expanded)\n",
    "    lp_apple.append(laplacian)\n",
    "\n",
    "# generate Laplacian Pyramid for orange\n",
    "orange_copy = gp_orange[5]\n",
    "lp_orange = [orange_copy]\n",
    "for i in range(5, 0, -1):\n",
    "    gaussian_expanded = cv2.pyrUp(gp_orange[i])\n",
    "    laplacian = cv2.subtract(gp_orange[i-1], gaussian_expanded)\n",
    "    lp_orange.append(laplacian)\n",
    "\n",
    "# Now add left and right halves of images in each level\n",
    "apple_orange_pyramid = []\n",
    "n = 0\n",
    "for apple_lap, orange_lap in zip(lp_apple, lp_orange):\n",
    "    n += 1\n",
    "    cols, rows, ch = apple_lap.shape\n",
    "    laplacian = np.hstack((apple_lap[:, 0:int(cols/2)], orange_lap[:, int(cols/2):]))\n",
    "    apple_orange_pyramid.append(laplacian)\n",
    "# now reconstruct\n",
    "apple_orange_reconstruct = apple_orange_pyramid[0]\n",
    "for i in range(1, 6):\n",
    "    apple_orange_reconstruct = cv2.pyrUp(apple_orange_reconstruct)\n",
    "    apple_orange_reconstruct = cv2.add(apple_orange_pyramid[i], apple_orange_reconstruct)\n",
    "\n",
    "cv2.imshow(\"apple\", apple)\n",
    "cv2.imshow(\"orange\", orange)\n",
    "cv2.imshow(\"apple_orange\", apple_orange)\n",
    "cv2.imshow(\"apple_orange_reconstruct\", apple_orange_reconstruct)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "apple = cv2.imread('opencv-master\\samples\\data\\lena.jpg')\n",
    "orange = cv2.imread('opencv-master\\samples\\data\\orange.jpg')\n",
    "apple_orange = np.hstack((apple[:, :256], orange[:, 256:]))\n",
    "cv2.imshow('apple',apple)\n",
    "cv2.imshow('orange',orange)\n",
    "cv2.imshow('apple_orange',apple_orange)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "#now  we remove the line(blending)\n",
    "#ist load\n",
    "#2nd  finnd gausain\n",
    "#3 lapsaian\n",
    "#join left helf and riht half adn reconstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#us ebinary image for better acuracy is a pytho  list  a numoya rray of(x,y)\n",
    "#coordinateos of boundary pints of object\n",
    "#contours \n",
    "#hirerchay is te optioan whcih contain informaton of ima\\ges\n",
    "\"\"\"\n",
    "In this video on OpenCV Python Tutorial For Beginners, I am going to show How to Find contours  and draw contours using OpenCV in Python.\n",
    "We will see what contours are. we will Learn to find contours, draw contours, we will see these functions : cv2.findContours(), cv2.drawContours().\n",
    "The function retrieves contours from the binary image. The contours are a useful tool for shape analysis and object detection and recognition. \"\"\"\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('opencv-master\\samples\\data\\opencv-logo.png')\n",
    "imgray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv2.threshold(imgray, 127, 255, 0)\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "print(\"Number of contours = \" + str(len(contours)))\n",
    "print(contours[0])\n",
    "\n",
    "cv2.drawContours(img, contours, -1, (0, 255, 0), 3) #-1 meams all element in img fro last contors-1\n",
    "cv2.drawContours(imgray, contours, -1, (0, 255, 0), 3)\n",
    "\n",
    "cv2.imshow('Image', img)\n",
    "cv2.imshow('Image GRAY', imgray)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#24 motion detection and trackng using open cv\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture('opencv-master\\samples\\data\\Megamind.avi')\n",
    "frame_width = int( cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "\n",
    "frame_height =int( cap.get( cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc('X','V','I','D')\n",
    "\n",
    "out = cv2.VideoWriter(\"output.avi\", fourcc, 5.0, (1280,720))\n",
    "\n",
    "ret, frame1 = cap.read()\n",
    "ret, frame2 = cap.read()\n",
    "#print(frame1.shape)\n",
    "while cap.isOpened():\n",
    "    diff = cv2.absdiff(frame1, frame2)\n",
    "    gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "    _, thresh = cv2.threshold(blur, 20, 255, cv2.THRESH_BINARY)\n",
    "    dilated = cv2.dilate(thresh, None, iterations=3)\n",
    "    contours, _ = cv2.findContours(dilated, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for contour in contours:\n",
    "        (x, y, w, h) = cv2.boundingRect(contour)\n",
    "\n",
    "        if cv2.contourArea(contour) < 900:\n",
    "            continue\n",
    "        cv2.rectangle(frame1, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        cv2.putText(frame1, \"Status: {}\".format('Movement'), (10, 20), cv2.FONT_HERSHEY_SIMPLEX,1, (0, 0, 255), 3)\n",
    "    #cv2.drawContours(frame1, contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "    image = cv2.resize(frame1, (1280,720))\n",
    "    out.write(image)\n",
    "    cv2.imshow(\"feed\", frame1)\n",
    "    frame1 = frame2\n",
    "    ret, frame2 = cap.read()\n",
    "\n",
    "    if cv2.waitKey(40) == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('opencv-master\\samples\\data\\shapes.png')\n",
    "imgGrey = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "_, thrash = cv2.threshold(imgGrey, 240, 255, cv2.THRESH_BINARY)\n",
    "contours, _ = cv2.findContours(thrash, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "cv2.imshow(\"img\", img)\n",
    "for contour in contours:\n",
    "    approx = cv2.approxPolyDP(contour, 0.01* cv2.arcLength(contour, True), True)\n",
    "    cv2.drawContours(img, [approx], 0, (0, 0, 0), 5)\n",
    "    x = approx.ravel()[0]\n",
    "    y = approx.ravel()[1] - 5\n",
    "    if len(approx) == 3:\n",
    "        cv2.putText(img, \"Triangle\", (x, y), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 0))\n",
    "    elif len(approx) == 4:\n",
    "        x1 ,y1, w, h = cv2.boundingRect(approx)\n",
    "        aspectRatio = float(w)/h\n",
    "        print(aspectRatio)\n",
    "        if aspectRatio >= 0.95 and aspectRatio <= 1.05:\n",
    "            cv2.putText(img, \"square\", (x, y), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 0))\n",
    "        else:\n",
    "            cv2.putText(img, \"rectangle\", (x, y), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 0))\n",
    "    elif len(approx) == 5:\n",
    "        cv2.putText(img, \"Pentagon\", (x, y), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 0))\n",
    "    elif len(approx) == 10:\n",
    "        cv2.putText(img, \"Star\", (x, y), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 0))\n",
    "    else:\n",
    "        cv2.putText(img, \"Circle\", (x, y), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 0))\n",
    "\n",
    "\n",
    "cv2.imshow(\"shapes\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture('opencv-master\\samples\\data\\Megamind.avi')\n",
    "while cap.isOpened():\n",
    "    ret,frame=cap.read()\n",
    "    cv2.imshow('inter',frame)\n",
    "    if cv2.waitKey(40)==27:\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histrogram gives overall idea about images\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "img=np.zeros((200,200),np.uint8)\n",
    "cv2.imshow('img',img)\n",
    "plt.hist(img.ravel(),256,[0,256])\n",
    "plt.show()\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "#because its clack mage so intesity is 0 x axis is intenity y axis is resolution (200*200)=40000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histrogram gives overall idea about images\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "img=np.zeros((200,200),np.uint8)\n",
    "cv2.rectangle(img,(0,100),(200,200),(255),-1)\n",
    "\n",
    "\n",
    "cv2.imshow('img',img)\n",
    "plt.hist(img.ravel(),256,[0,256])\n",
    "plt.show()\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "#because its clack mage so intesity is 0 x axis is intenity y axis is resolution (200*200)=40000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histrogram gives overall idea about images\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "img=np.zeros((200,200),np.uint8)\n",
    "cv2.rectangle(img,(0,100),(200,200),(255),-1)\n",
    "cv2.rectangle(img,(0,50),(100,100),(127),-1)\n",
    "\n",
    "cv2.imshow('img',img)\n",
    "plt.hist(img.ravel(),256,[0,256])\n",
    "plt.show()\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "#because its clack mage so intesity is 0 x axis is intenity y axis is resolution (200*200)=40000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histrogram gives overall idea about images\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "img=cv2.imread('opencv-master\\samples\\data\\lena.jpg')\n",
    "cv2.imshow('img',img)\n",
    "plt.hist(img.ravel(),256,[0,256])\n",
    "plt.show()\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "#because its clack mage so intesity is 0 x axis is intenity y axis is resolution (200*200)=40000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "img=cv2.imread('opencv-master\\samples\\data\\lena.jpg')\n",
    "b,g,r=cv2.split(img)\n",
    "cv2.imshow('b',b)\n",
    "cv2.imshow('g',g)\n",
    "cv2.imshow('r',r)\n",
    "plt.hist(b.ravel(),256,[0,256])\n",
    "plt.hist(g.ravel(),256,[0,256])\n",
    "plt.hist(r.ravel(),256,[0,256])\n",
    "plt.show()\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calhist method\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "img=cv2.imread('opencv-master\\samples\\data\\lena.jpg')\n",
    "hist=cv2.calcHist([img],[0],None,[256],[0,256]) #jhist size 256 then min and max range\n",
    "plt.plot(hist)\n",
    "plt.show()\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#template images\n",
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread(\"opencv-master\\samples\\data\\messi5.jpg\")\n",
    "grey_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "template = cv2.imread(\"opencv-master\\samples\\data\\messi_face.jpg\", 0)\n",
    "w,h=template.shape[::-1]\n",
    "\n",
    "res = cv2.matchTemplate(grey_img, template, cv2.TM_CCORR_NORMED )\n",
    "print(res)\n",
    "threshold = 0.99;\n",
    "loc = np.where(res >= threshold)\n",
    "print(loc)\n",
    "for pt in zip(*loc[::-1]):\n",
    "    cv2.rectangle(img, pt, (pt[0] + w, pt[1] + h), (0, 0, 255), 2)\n",
    "\n",
    "cv2.imshow(\"img\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#28\n",
    "#detect4#hough transform basics\n",
    "\"\"\"\n",
    "n this video on OpenCV Python Tutorial For Beginners, we are  going to understand the concept of the Hough Transform and Hough Line Transform Theory.\n",
    "\n",
    "OpenCV implements two kind of Hough Line Transforms\n",
    "The Standard Hough Transform  (HoughLines method)\n",
    "The Probabilistic Hough Line Transform  (HoughLinesP method)\"\"\"\n",
    "#half transformatin\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "lines = cv.HoughLines(image, rho, theta, threshold) \n",
    "image : source image.\n",
    "lines : Output vector of lines. Each line is represented by a 2 or 3 element vector (,) or (,,votes) . \n",
    "        is the distance from the coordinate origin (0,0) (top-left corner of the image).  is the line rotation angle in radians . votes is the value of accumulator.\n",
    "rho : Distance resolution of the accumulator in pixels.\n",
    "theta : Angle resolution of the accumulator in radians.\n",
    "threshold : Accumulator threshold parameter. Only those lines are returned that get enough votes ( greater then threshold ).\n",
    "\n",
    "OpenCV is an image processing library created by Intel and later supported by Willow Garage and now maintained by Itseez. opencv is available on Mac, Windows, Linux. Works in C, C++, and Python.\n",
    "it is Open Source and free. opencv is easy to use and install.\n",
    "\n",
    "Starting with an overview of what the course will be covering, we move on to discussing morphological operations and practically learn how they work on images. We will then learn contrast enhancement using equalization and contrast limiting.  Finally we will learn 3 methods to subtract the background from the video and implement them using OpenCV.\"\"\"\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('opencv-master\\samples\\data\\sudoku.png')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
    "cv2.imshow('edges', edges)\n",
    "lines = cv2.HoughLines(edges, 1, np.pi / 180, 200)\n",
    "\n",
    "for line in lines:\n",
    "    rho,theta = line[0]\n",
    "    a = np.cos(theta)\n",
    "    b = np.sin(theta)\n",
    "    x0 = a * rho\n",
    "    y0 = b * rho\n",
    "    # x1 stores the rounded off value of (r * cos(theta) - 1000 * sin(theta))\n",
    "    x1 = int(x0 + 1000 * (-b))\n",
    "    # y1 stores the rounded off value of (r * sin(theta)+ 1000 * cos(theta))\n",
    "    y1 = int(y0 + 1000 * (a))\n",
    "    # x2 stores the rounded off value of (r * cos(theta)+ 1000 * sin(theta))\n",
    "    x2 = int(x0 - 1000 * (-b))\n",
    "    # y2 stores the rounded off value of (r * sin(theta)- 1000 * cos(theta))\n",
    "    y2 = int(y0 - 1000 * (a))\n",
    "    cv2.line(img, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "\n",
    "\n",
    "cv2.imshow('image', img)\n",
    "k = cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hough line probablistic method give better result\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread('opencv-master\\samples\\data\\sudoku.png')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray,50,150,apertureSize = 3)\n",
    "cv2.imshow('edges', edges)\n",
    "lines = cv2.HoughLinesP(edges,1,np.pi/180,100,minLineLength=100,maxLineGap=10)\n",
    "for line in lines:\n",
    "    x1,y1,x2,y2 = line[0]\n",
    "    cv2.line(img,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "\n",
    "cv2.imshow('image', img)\n",
    "k = cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#road line detection\n",
    "import matplotlib.pylab as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('opencv-master\\samples\\data\\sudoku.png')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "print(image.shape)\n",
    "height = image.shape[0]\n",
    "width = image.shape[1]\n",
    "\n",
    "region_of_interest_vertices = [\n",
    "    (0, height),\n",
    "    (width/2, height/2),\n",
    "    (width, height)\n",
    "]\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    mask = np.zeros_like(img)\n",
    "    channel_count = img.shape[2]\n",
    "    match_mask_color = (255,) * channel_count\n",
    "    cv2.fillPoly(mask, vertices, match_mask_color)\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "cropped_image = region_of_interest(image,\n",
    "                np.array([region_of_interest_vertices], np.int32),)\n",
    "\n",
    "plt.imshow(cropped_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "img = cv.imread('opencv-master\\samples\\data\\smarties.png')\n",
    "output = img.copy()\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "gray = cv.medianBlur(gray, 5)\n",
    "circles = cv.HoughCircles(gray, cv.HOUGH_GRADIENT, 1, 20,\n",
    "                          param1=50, param2=30, minRadius=0, maxRadius=0)\n",
    "detected_circles = np.uint16(np.around(circles))\n",
    "for (x, y ,r) in detected_circles[0, :]:\n",
    "    cv.circle(output, (x, y), r, (0, 0, 0), 3)\n",
    "    cv.circle(output, (x, y), 2, (0, 255, 255), 3)\n",
    "\n",
    "\n",
    "cv.imshow('output',output)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#face detection\n",
    "#if image cntain fce thast call positivr umage\n",
    "#other wis e negative\n",
    "import cv2\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')#train model\n",
    "# Read the input image\n",
    "#img = cv2.imread('test.png')\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    _, img = cap.read()\n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "    for (x, y , w ,h) in faces:\n",
    "        cv2.rectangle(img, (x,y), (x+w, y+h), (255, 0 , 0), 3)\n",
    "\n",
    "    # Display the output\n",
    "    cv2.imshow('img', img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "#eye detection with face\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye_tree_eyeglasses.xml')\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    _, img = cap.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "    for (x, y , w ,h) in faces:\n",
    "        cv2.rectangle(img, (x,y), (x+w, y+h), (255, 0 , 0), 3)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "        for (ex, ey ,ew, eh) in eyes:\n",
    "            cv2.rectangle(roi_color, (ex,ey), (ex+ew, ey+eh), (0, 255, 0), 5)\n",
    "\n",
    "    # Display the output\n",
    "    cv2.imshow('img', img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "#https://docs.opencv.org/4.0.0/d7/d8b/tutorial_py_face_detection.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#harris corner detector\n",
    "import numpy as np\n",
    "import cv2 \n",
    "\n",
    "img = cv2.imread('opencv-master\\samples\\data\\chessboard.png')\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "gray = cv2.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "gray = np.float32(gray)\n",
    "dst = cv2.cornerHarris(gray, 2, 3, 0.04)\n",
    "\n",
    "dst = cv2.dilate(dst, None)\n",
    "\n",
    "img[dst > 0.01 * dst.max()] = [0, 0, 255]\n",
    "\n",
    "cv2.imshow('dst', img)\n",
    "\n",
    "if cv2.waitKey(0) & 0xff == 27:\n",
    "    cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shetomasi corner detector\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "img = cv.imread('opencv-master\\samples\\data\\pic1.png')\n",
    "\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "corners = cv.goodFeaturesToTrack(gray, 100, 0.01, 10)\n",
    "\n",
    "corners = np.int0(corners)\n",
    "\n",
    "for i in corners:\n",
    "    x, y = i.ravel()\n",
    "    cv.circle(img, (x, y), 3, [255, 255, 0], -1)\n",
    "\n",
    "cv.imshow('Shi-Tomasi Corner Detector', img)\n",
    "\n",
    "if cv.waitKey(0) & 0xff == 27:\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
